import operator
import random
import numpy as np
from deap import base, creator, tools, gp
import networkx as nx
from deap.gp import graph
from networkx.drawing.nx_agraph import graphviz_layout
from collections import OrderedDict
# import matplotlib.pyplot as plt
from liu.DatasetReader import createNode
from Class.Taskflow import TaskFlow
from liu.exetime import computing_Task, computing_upload_time
import multiprocessing
import copy

from llm_engine.llm_evolutionary_operators import llm_mutated_expressions, \
    llm_crossover_expressions
from utils.convert_tree2expression import tree_to_expression, expression_to_tree
from utils.openai_interface import OpenAIInterface

#  ç»Ÿä¸€å‚æ•°è®¾ç½®
NUM_NODES = 10                 # èŠ‚ç‚¹æ•°
NUM_TASKFLOWS = 20             # ä»»åŠ¡æµæ•°
POP_SIZE = 20                  # ç§ç¾¤è§„æ¨¡
NGEN = 2                       # è¿›åŒ–ä»£æ•°
CXPB = 0.9                     # äº¤å‰æ¦‚ç‡
MUTPB = 0.1                    # å˜å¼‚æ¦‚ç‡
TOURNAMENT_SIZE = 5           # é”¦æ ‡èµ›é€‰æ‹©è§„æ¨¡
HEIHT_LIMIT = 8               # æœ€å¤§æ ‘é«˜
NUM_TREES = 2                 # æ¯ä¸ªä¸ªä½“ä¸­æ ‘çš„æ•°é‡
NUM_RUNS = 2                # é‡å¤è¿è¡Œæ¬¡æ•°ï¼ˆç”¨äºç»Ÿè®¡å‡å€¼ï¼‰
EVAL_TEST_TASKFLOWS = 1       # æµ‹è¯•æ—¶çš„ä»»åŠ¡æµæ•°
ELITISM_NUM = int(POP_SIZE * 0.05)  # ç²¾è‹±ä¸ªä½“çš„æ•°é‡
LLM_INTERFACE = OpenAIInterface()
NUM_TEST_SETS = 1             # æµ‹è¯•é›†æ•°é‡

def initIndividual(container, func, pset, size):
    return container(gp.PrimitiveTree(func(pset[i])) for i in range(size))

def cxOnePointListOfTrees(ind1, ind2, pset=None, llm_interface=None):
    assert pset is not None, "âŒ `pset` ä¸èƒ½ä¸º Noneï¼"
    HEIGHT_LIMIT = 8
    print("ğŸš€ è¿›å…¥ cxOnePointListOfTrees å‡½æ•°")

    try:
        for idx, (tree1, tree2) in enumerate(zip(ind1, ind2)):
            print(f"\n===== ğŸ§¬ æ­£åœ¨å¤„ç†ç¬¬ {idx} æ£µå­æ ‘ =====")
            print("ğŸ”µ åŸå§‹ tree1:", str(tree1))
            print("ğŸ”µ åŸå§‹ tree2:", str(tree2))
            print(f"ğŸ“¦ å½“å‰å­æ ‘ç±»å‹: {type(tree1)} / {type(ind1[idx])}")

            if idx >= len(pset):
                raise IndexError(f"âŒ idx {idx} è¶…è¿‡äº† pset çš„å®šä¹‰èŒƒå›´")

            expr1 = tree_to_expression(tree1)
            expr2 = tree_to_expression(tree2)
            print(f"ğŸ” è½¬æ¢åçš„è¡¨è¾¾å¼:\n  expr1: {expr1}\n  expr2: {expr2}")

            print("âš™ï¸ è°ƒç”¨ llm_crossover_expressions æ‰§è¡Œäº¤å‰...")
            if idx == 0:
                new_expressions = llm_crossover_expressions(llm_interface, [expr1, expr2], 0)
                pset_idx = 0
            elif idx == 1:
                new_expressions = llm_crossover_expressions(llm_interface, [expr1, expr2], 1)
                pset_idx = 1
            else:
                raise ValueError(f"âŒ ä¸æ”¯æŒçš„ idx å€¼: {idx}")

            print("ğŸ§ª LLM ç”Ÿæˆçš„æ–°è¡¨è¾¾å¼:", new_expressions)

            # æ„å»ºæ–°æ ‘å¹¶åŠ å¼‚å¸¸æ•è·
            try:
                new_tree1 = gp.PrimitiveTree.from_string(expression_to_tree(new_expressions[0]), pset[pset_idx])
            except Exception as e:
                print(f"âŒ new_tree1 æ„å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹ tree1")
                new_tree1 = tree1

            try:
                new_tree2 = gp.PrimitiveTree.from_string(expression_to_tree(new_expressions[1]), pset[pset_idx])
            except Exception as e:
                print(f"âŒ new_tree2 æ„å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹ tree2")
                new_tree2 = tree2

            print(f"ğŸŒ² æ–°æ ‘é«˜åº¦: tree1: {new_tree1.height}, tree2: {new_tree2.height}")

            # åˆ¤æ–­æ˜¯å¦è¶…é«˜å¹¶æ„é€ æ–° individual
            if new_tree1.height > HEIGHT_LIMIT:
                print(f"âš ï¸ new_tree1 è¶…å‡ºé«˜åº¦é™åˆ¶ï¼Œä½¿ç”¨åŸå§‹ individual1")
                new_individual1 = ind1[idx]
            else:
                new_individual1 = type(ind1[idx])(new_tree1)

            if new_tree2.height > HEIGHT_LIMIT:
                print(f"âš ï¸ new_tree2 è¶…å‡ºé«˜åº¦é™åˆ¶ï¼Œä½¿ç”¨åŸå§‹ individual2")
                new_individual2 = ind2[idx]
            else:
                new_individual2 = type(ind2[idx])(new_tree2)

            # æ›¿æ¢åŸä¸ªä½“
            ind1[idx], ind2[idx] = new_individual1, new_individual2

        print("âœ… æ‰€æœ‰å­æ ‘äº¤å‰å®Œæˆï¼Œè¿”å› ind1, ind2")
        return ind1, ind2

    except Exception as e:
        print("âŒ äº¤å‰è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼š", e)
        raise e

def mutUniformListOfTrees(individual, pset=None, llm_interface=None):
    assert pset is not None, "âŒ `pset` ä¸èƒ½ä¸º Noneï¼"
    HEIGHT_LIMIT = 8
    try:
        for idx, tree in enumerate(individual):
            if idx >= len(pset):
                raise IndexError(f"idx {idx} è¶…è¿‡äº†psetçš„å®šä¹‰èŒƒå›´")
            print(f"===== å˜å¼‚å¤„ç†ç¬¬ {idx} æ£µå­æ ‘ =====")
            print("ğŸŸ¢ åŸå§‹ tree (str):", str(tree))

            expr = tree_to_expression(tree)
            print("ğŸ” è½¬æ¢ä¸ºè¡¨è¾¾å¼:", expr)

            # è°ƒç”¨ LLM æ‰§è¡Œå˜å¼‚
            new_expression = llm_mutated_expressions(llm_interface, expr, idx)
            print("ğŸ¯ LLM ç”Ÿæˆçš„æ–°è¡¨è¾¾å¼:", new_expression)

            # å°è¯•æ„é€ æ–°æ ‘
            try:
                new_tree = gp.PrimitiveTree.from_string(expression_to_tree(new_expression), pset[idx])
            except Exception as e:
                print(f"âŒ æ„å»º new_tree å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹ tree")
                new_tree = tree

            # åˆ¤æ–­é«˜åº¦é™åˆ¶
            if new_tree.height > HEIGHT_LIMIT:
                print(f"âš ï¸ new_tree è¶…å‡ºé«˜åº¦é™åˆ¶ï¼Œä½¿ç”¨åŸå§‹ tree")
                new_individual = individual[idx]
            else:
                new_individual = type(individual[idx])(new_tree)

            # æ›¿æ¢ä¸ªä½“ä¸­å¯¹åº”å­æ ‘
            individual[idx] = new_individual

        print("âœ… æ‰€æœ‰å­æ ‘å˜å¼‚å®Œæˆï¼Œè¿”å› individual")
        return (individual,)

    except Exception as e:
        print(f"âŒ å˜å¼‚è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼š{e}ï¼Œè¿”å›åŸå§‹ individual")
        return (individual,)

def varAnd(population, toolbox, cxpb, mutpb, pset):
    offspring = [toolbox.clone(ind) for ind in population]
    evlpb=cxpb/(cxpb+mutpb)
    if random.random() < evlpb:
        for i in range(1, len(offspring), 2):
            offspring[i - 1], offspring[i] = toolbox.mate(offspring[i - 1],
                                                          offspring[i], pset,LLM_INTERFACE)
            del offspring[i - 1].fitness.values, offspring[i].fitness.values

    else:
        for i in range(len(offspring)):
            offspring[i], = toolbox.mutate(offspring[i],pset,LLM_INTERFACE)
            del offspring[i].fitness.values

    return offspring

def sortPopulation(toolbox, population):#å‡½æ•° sortPopulation å¯¹è¾“å…¥çš„ç§ç¾¤è¿›è¡Œæ’åºï¼ˆæŒ‰ç…§é€‚åº”åº¦,å†’æ³¡æ’åºï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ’åºåçš„ç§ç¾¤å‰¯æœ¬ï¼Œè€Œä¸ä¼šä¿®æ”¹åŸå§‹çš„population
    populationCopy = [toolbox.clone(ind) for ind in population]
    popsize = len(population)
    for j in range(popsize):
        sign = False
        for i in range(popsize-1-j):
            sum_fit_i = populationCopy[i].fitness.values
            sum_fit_i_1 = populationCopy[i+1].fitness.values
            if sum_fit_i > sum_fit_i_1:
                populationCopy[i], populationCopy[i+1] = populationCopy[i+1], populationCopy[i]
                sign = True
        if not sign:
            break
    return populationCopy

def evaluate_offspring_in_parallel(offspring, taskflows, nodes, pset, work_function):

    pool = multiprocessing.Pool()
    results = []

    for ind in offspring:
        tasks_copy = copy.deepcopy(taskflows)
        nodes_copy = copy.deepcopy(nodes)
        result = pool.apply_async(work_function, (ind, tasks_copy, nodes_copy, pset,))
        results.append(result)

    pool.close()
    pool.join()

    fitnesses = [res.get() for res in results]
    return fitnesses

def evaluate_on_testSets(individual, nodes, num_TaskFlow, pset):
    results = []
    for i in range(NUM_TEST_SETS):
        nodes_copy = copy.deepcopy(nodes)
        taskflows = createTaskFlows(num_TaskFlow, genre=1, seed=i)
        fitness = work_processing(individual, taskflows, nodes_copy, pset)
        results.append(fitness[0])
    return results

def eaSimple(population, toolbox,taskflows,nodes,num_TaskFlow,num_nodes, cxpb, mutpb, ngen, elitism,pset,llm_interface,min_fitness_values=[],genre_min_fitness_values=[],stats=None,
             halloffame=None, verbose=__debug__, ):
    logbook = tools.Logbook()
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])

    # ç­›é€‰å‡ºæœªé€‚åº”åº¦è¯„ä¼°çš„ä¸ªä½“
    invalid_ind = [ind for ind in population if not ind.fitness.valid]
    # é€‚åº”åº¦è¯„ä¼°(è®­ç»ƒé›†)
    fitnesses = evaluate_offspring_in_parallel(invalid_ind, taskflows, nodes, pset, work_processing)

    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    if halloffame is not None:
        halloffame.update(population)

    record = stats.compile(population) if stats else {}
    min_fitness_values.append(record["fitness"]["min"])
    logbook.record(gen=0, nevals=len(invalid_ind), **record)
    if verbose:
        print(logbook.stream)

    sorted_elite = sortPopulation(toolbox, population)[:elitism]
    # é€‚åº”åº¦è¯„ä¼°ï¼ˆéªŒè¯é›†ï¼‰
    value_list = evaluate_on_testSets(sorted_elite[0], nodes, num_TaskFlow, pset)
    genre_min_fitness_values.append(sum(value_list) / NUM_TEST_SETS)

    # å¼€å¯è¿›åŒ–è¿‡ç¨‹
    for gen in range(1, ngen + 1):
        taskflows = createTaskFlows(num_TaskFlow,0,gen)

        # Select the next generation individuals
        offspring = toolbox.select(population, len(population)-elitism) # è¿™è¡Œä»£ç ä½¿ç”¨é€‰æ‹©æ“ä½œä»å½“å‰ç§ç¾¤ä¸­é€‰æ‹©ä¸åŸç§ç¾¤ç›¸åŒæ•°é‡çš„ä¸ªä½“ï¼Œè¿™äº›ä¸ªä½“æ„æˆæ–°çš„åä»£ã€‚,åªæ˜¯é€‰æ‹©çš„è¿‡ç¨‹ä¸º3é€‰ä¸€

        offspring = varAnd(offspring, toolbox, cxpb, mutpb, pset)

        offspring[:] = sorted_elite + offspring

        # é€‚åº”åº¦è¯„ä¼°ï¼ˆè®­ç»ƒé›†ï¼‰
        fitnesses = evaluate_offspring_in_parallel(offspring,taskflows,nodes,pset,work_processing)

        for ind, fit in zip(offspring, fitnesses):
            ind.fitness.values = fit   #å°†è¿™äº›è®¡ç®—å‡ºçš„é€‚åº”åº¦å€¼èµ‹ç»™å¯¹åº”çš„ä¸ªä½“ï¼Œä½¿å¾—å®ƒä»¬çš„é€‚åº”åº¦å±æ€§å˜ä¸ºæœ‰æ•ˆã€‚

        # Update the hall of fame with the generated individuals
        if halloffame is not None:
            halloffame.update(offspring)

        # Replace the current population by the offspring
        population[:] = offspring

        # Append the current generation statistics to the logbook
        record = stats.compile(population) if stats else {}
        min_fitness_values.append(record["fitness"]["min"]) #æˆ‘åŠ çš„
        logbook.record(gen=gen, nevals=len(invalid_ind), **record)

        if verbose:
            print(logbook.stream)

        sorted_elite = sortPopulation(toolbox, population)[:elitism]

        # é€‚åº”åº¦è¯„ä¼°ï¼ˆæµ‹è¯•é›†ï¼‰
        value_list = evaluate_on_testSets(sorted_elite[0], nodes, num_TaskFlow, pset)
        genre_min_fitness_values.append(sum(value_list) / NUM_TEST_SETS)

    return population, logbook ,genre_min_fitness_values,sorted_elite[0]

def is_number(string):#åˆ›å»ºä¸€ä¸ªå‡½æ•° is_numberï¼Œç”¨äºæ£€æŸ¥ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å¦å¯ä»¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚å¦‚æœå¯ä»¥ï¼Œåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    try:
        float(string)
        return True
    except ValueError:
        return False

def count_leaf_types(tree):
    leaf_count={}
    name_mapping = {
        'ARG0': 'a',
        'ARG1': 'b',
        'ARG2': 'c',
        'ARG3': 'd',
        'ARG4': 'e',
        'ARG5': 'f'
    }
    """ç»Ÿè®¡æ¯ç§å¶å­èŠ‚ç‚¹çš„æ•°é‡"""
    for x in tree:
        if isinstance(x, gp.Terminal):  # å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹
            leaf_name = x.name
            if leaf_name in name_mapping:
                leaf_name = name_mapping[leaf_name]
            leaf_count[leaf_name] = leaf_count.get(leaf_name, 0) + 1
    return leaf_count


def protect_div(left, right):
    with np.errstate(divide='ignore', invalid='ignore'):
        x = np.divide(left, right)
        if isinstance(x, np.ndarray):
            x[np.isinf(x)] = 1
            x[np.isnan(x)] = 1
        elif np.isinf(x) or np.isnan(x):
            x = 1
    return x

def createTaskFlows(num_TaskFlow,genre,seed): #åˆ›å»ºå¤šä¸ªå·¥ä½œæµ #kä¸ºä»»åŠ¡æµéšæœºç§å­
    lambda_rate = 1  # å¹³å‡åˆ°è¾¾é€Ÿç‡ (Î»ï¼Œæ¯å•ä½æ—¶é—´å¹³å‡åˆ°è¾¾ä»»åŠ¡æ•°)
    np.random.seed(seed)
    interarrival_times = np.random.exponential(1 / lambda_rate, num_TaskFlow)  # ä¼šç”Ÿæˆä¸€ä¸ªåŒ…å« num_tasks ä¸ªä»»åŠ¡åˆ°è¾¾æ—¶é—´é—´éš”çš„æ•°ç»„

    # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„åˆ°è¾¾æ—¶é—´ï¼ˆé€šè¿‡ç´¯åŠ é—´éš”æ—¶é—´ï¼‰
    arrival_times = np.cumsum(interarrival_times)
    taskflows=[TaskFlow(id,arrival_time,genre,id + (seed) * num_TaskFlow) for id, arrival_time in zip(range(num_TaskFlow), arrival_times)]
    return taskflows

def present_time_update(present_time,taskflows):#åªæ›´æ–°é‚£äº›æœªå®Œæˆä»»åŠ¡çš„å½“å‰æ—¶é—´ï¼Œæ‰€ä»¥å½“ä¸€ä¸ªä»»åŠ¡å·²å®Œæˆæ—¶ï¼Œå®ƒçš„å½“å‰æ—¶é—´å°±æ˜¯å®Œæˆæ—¶é—´
    for taskflow in taskflows:
        for task in taskflow.tasks:
            if task.finish is False:
                task.present_time=present_time

def find_earlist_time(queue1,queue2):
    # ä½¿ç”¨ sort() æ–¹æ³•æ’åº
    queue1.sort(key=lambda x: x[1])
    queue2.sort(key=lambda x: x[1])
    task_queue1 = []
    task_queue2 = []
    if len(queue1)!=0 and len(queue2)!=0:
        min_time=min(queue1[0][1],queue2[0][1])
        for event in queue1:
            if event[1]==min_time:
                task_queue1.append(event[0])
        for event in queue2:
            if event[1]==min_time:
                task_queue2.append(event[0])
    elif len(queue1)==0  and len(queue2)!=0:
        min_time = queue2[0][1]
        for event in queue2:
            if event[1]==min_time:
                task_queue2.append(event[0])
    elif len(queue1)!=0  and len(queue2)==0:
        min_time = queue1[0][1]
        for event in queue1:
            if event[1]==min_time:
                task_queue1.append(event[0])
    return queue1,queue2,task_queue1,task_queue2

#decode1å‡½æ•°ä¸­éœ€è¦å¢åŠ ä¸€ä¸ªçº¦æŸæ¡ä»¶ï¼Œåˆ¤æ–­èŠ‚ç‚¹çš„ramï¼Œgpuï¼Œcpuå¤Ÿä¸å¤Ÿç”¨ï¼Œè¦åœ¨å¤Ÿç”¨çš„èŠ‚ç‚¹ä¸­é€‰æ‹©
def decode1(individual, task, nodes, taskflows,pset):
    heuristic_1 = gp.compile(expr=individual[0], pset=pset[0])
    scores = []
    # k=task.taskflow_id #ä»»åŠ¡æ‰€åœ¨ä»»åŠ¡æµï¼Œåœ¨å¤šä»»åŠ¡æµä¸­çš„ä½ç½®
    for node in nodes:
        heuristic_score = heuristic_1(computing_Task(task,node),task.present_time-task.arrivetime,
                                      len(task.descendant),computing_upload_time(task,node))
        scores.append((node, heuristic_score))
    best_node = max(scores, key=lambda x: x[1])[0]
    return best_node #æ‰¾åˆ°èŠ‚ç‚¹æœ¬èº«

def decode2(individual, node, taskflows,nodes, pset):
    heuristic_2 = gp.compile(expr=individual[1], pset=pset[1])
    scores = []
    for task in node.waiting_queue:
        k = task.taskflow_id#ä»»åŠ¡æ‰€åœ¨ä»»åŠ¡æµï¼Œåœ¨å¤šä»»åŠ¡æµä¸­çš„ä½ç½®
        heuristic_score = heuristic_2(computing_Task(task,node),task.present_time-task.arrivetime,
                                      len(task.descendant),taskflows[k].find_descendant_avg_time(taskflows,task,nodes),
                                      0.1*computing_upload_time(task,node)) #ä»»åŠ¡ç»™åç»§ä¼ é€’æ¶ˆæ¯çš„æ—¶é—´å–ä¸Šä¼ æ—¶é—´çš„0.1
        scores.append((task, heuristic_score))
    #print(scores)
    best_task = max(scores, key=lambda x : x[1])[0]
    return best_task #è¿”å›æ‰¾åˆ°çš„ä»»åŠ¡æœ¬èº«

def work_processing(individual, taskflows, nodes, pset):
    def sanitize_task_id(task):
        return getattr(task, "global_id", f"Task {task.id}")

    def sanitize_node_id(node):
        return f"N{node.id}({node.node_type})"

    queue1 = []  # æœªæ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
    queue2 = []  # æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡é˜Ÿåˆ—
    present_time = 0
    present_time_update(present_time, taskflows)

    print("ğŸš€ å¼€å§‹ä»»åŠ¡æµè°ƒåº¦æ¨¡æ‹Ÿ...")
    for taskflow in taskflows:
        tasks = taskflow.find_predecessor_is_zero()
        for task in tasks:
            queue1.append((task, task.arrivetime))
            print(f"ğŸ•“ ä»»åŠ¡ Task {task.task_id} åˆ°è¾¾æ—¶é—´ {task.arrivetime} å·²åŠ å…¥ queue1")

    while len(queue2) != 0 or len(queue1) != 0:
        queue1, queue2, task_queue1, task_queue2 = find_earlist_time(queue1, queue2)

        if len(task_queue1) != 0:
            present_time_update(present_time=queue1[0][1], taskflows=taskflows)
            print(f"\nğŸ“ æ—¶é—´æ¨è¿›è‡³ {queue1[0][1]}ï¼Œè°ƒåº¦ä»¥ä¸‹å¾…æ‰§è¡Œä»»åŠ¡ï¼š")

            for task in task_queue1:
                node = decode1(individual, task, nodes, taskflows, pset)
                task.node = node
                print(f"ğŸ” Task {task.task_id} åˆ†é…ç»™ Node {node.node_id}")

                if task.present_time >= node.begin_idle_time:
                    computing_Task_time = computing_Task(task, node) + computing_upload_time(task, node)
                    endtime = task.present_time + computing_Task_time
                    task.endtime = endtime
                    queue2.append((task, endtime))
                    node.begin_idle_time = endtime
                    print(f"âœ… Task {task.task_id} å¼€å§‹æ‰§è¡Œï¼Œé¢„è®¡å®Œæˆäº {endtime}")
                else:
                    node.waiting_queue.append(task)
                    print(f"â³ Task {task.task_id} åŠ å…¥ Node {node.node_id} çš„ç­‰å¾…é˜Ÿåˆ—")
                queue1 = [item for item in queue1 if item[0] != task]

        if len(task_queue2) != 0:
            print(f"\nğŸ æ—¶é—´æ¨è¿›è‡³ {queue2[0][1]}ï¼Œä»¥ä¸‹ä»»åŠ¡å®Œæˆï¼š")
            for finish_event in task_queue2:
                finish_event.finish = True
                print(f"âœ… Task {finish_event.task_id} æ‰§è¡Œå®Œæˆ")

            present_time_update(present_time=queue2[0][1], taskflows=taskflows)

            for task in task_queue2:
                i = task.taskflow_id
                TaskFlow = taskflows[i]

                if len(task.descendant) != 0:
                    id = TaskFlow.tasks.index(task)
                    descendant_tasks = []
                    for b in task.descendant:
                        TaskFlow.tasks[b].predecessor.remove(id)
                        if len(TaskFlow.tasks[b].predecessor) == 0:
                            descendant_tasks.append(TaskFlow.tasks[b])

                    for descendant_task in descendant_tasks:
                        queue1.append((descendant_task, descendant_task.present_time))
                        print(f"ğŸ”„ åç»§ä»»åŠ¡ Task {descendant_task.task_id} å‰é©±å·²å®Œæˆï¼ŒåŠ å…¥ queue1")

                else:
                    TaskFlow.finish_time = max(TaskFlow.finish_time, queue2[0][1])
                    print(f"ğŸ¯ TaskFlow {i} å¯èƒ½å®Œæˆï¼Œå½“å‰è®°å½•å®Œæˆæ—¶é—´ä¸º {TaskFlow.finish_time}")

                if len(task.node.waiting_queue) != 0:
                    next_task = decode2(individual, task.node, taskflows, nodes, pset)
                    task.node.waiting_queue.remove(next_task)
                    computing_Task_time = computing_Task(next_task, task.node) + \
                                          computing_upload_time(next_task, task.node) + \
                                          0.1 * computing_upload_time(task, task.node)
                    next_task.endtime = next_task.present_time + computing_Task_time
                    queue2.append((next_task, next_task.endtime))
                    task.node.begin_idle_time = next_task.endtime
                    print(f"ğŸ“¤ Node {task.node.node_id} ä»ç­‰å¾…é˜Ÿåˆ—ä¸­è°ƒåº¦ Task {next_task.task_id} æ‰§è¡Œï¼Œå®Œæˆäº {next_task.endtime}")
                queue2 = [item for item in queue2 if item[0] != task]

    print("\nğŸ“Š æ‰€æœ‰ä»»åŠ¡æµè°ƒåº¦ç»“æŸï¼Œç»Ÿè®¡å10ä¸ªä»»åŠ¡æµå¹³å‡å®Œæˆæ—¶é—´ï¼š")
    sum_time = 0
    taskflows_number = 0
    for j in taskflows[10:]:
        taskflows_number += 1
        print(f"ğŸ§¾ TaskFlow å®Œæˆæ—¶é—´ï¼š{j.finish_time}ï¼Œå¼€å§‹æ—¶é—´ï¼š{j.all_arrive_time}")
        sum_time += (j.finish_time - j.all_arrive_time)

    avg_time = sum_time / taskflows_number if taskflows_number else 0
    print(f"\nğŸ“ˆ å¹³å‡å®Œæˆæ—¶é—´ï¼ˆå10ä¸ªä»»åŠ¡æµï¼‰: {avg_time}")
    return (avg_time,)


# def work_processing(individual,taskflows,nodes,pset): #taskflowsæœ¬ä½“å’Œé™„å±å±æ€§æœ‰æ²¡æœ‰æ”¹å˜ï¼Ÿâ€»ç­‰å·ä¼ çš„éƒ½æ˜¯åœ°å€
#     queue1=[]               # æœªæ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
#     queue2=[]               # æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡é˜Ÿåˆ—
#     present_time=0
#     present_time_update(present_time, taskflows)
#
#
#     """
#     queueä¸­å…ƒç´ ä¸ºå…ƒç»„ ï¼ˆä»»åŠ¡æœ¬èº«ï¼Œä»»åŠ¡çš„å¼€å§‹æ—¶é—´æˆ–ä»»åŠ¡çš„ç»“æŸæ—¶é—´ï¼‰
#     """
#
#     print("ğŸš€ å¼€å§‹ä»»åŠ¡æµè°ƒåº¦æ¨¡æ‹Ÿ...")
#     for taskflow in taskflows:
#         tasks = taskflow.find_predecessor_is_zero()
#         for task in tasks:
#             queue1.append((task, task.arrivetime)) #å…ƒç»„
#             print(f"ğŸ•“ ä»»åŠ¡ Task {task.task_id} åˆ°è¾¾æ—¶é—´ {task.arrivetime} å·²åŠ å…¥ queue1")
#
#     while(len(queue2) != 0 or len(queue1) != 0):
#         # æ‰¾åˆ°æœ€æ—©å‘ç”Ÿçš„äº‹ä»¶
#         queue1, queue2, task_queue1, task_queue2 = find_earlist_time(queue1,queue2)
#
#         if len(task_queue1)!=0:#åœ¨queue1å’Œqueue2ä¸­æ—¶é—´æœ€å°çš„ä»»åŠ¡åœ¨queue1
#             present_time_update(present_time=queue1[0][1],taskflows=taskflows)#æ›´æ–°æ‰€æœ‰queue2å’Œqueue1ä¸­ä»»åŠ¡å’Œæ‰€æœ‰nodeä¸­ç­‰å¾…é˜Ÿåˆ—ä¸­ä»»åŠ¡çš„å½“å‰æ—¶é—´ å’Œé¢„å¤„ç†ä»»åŠ¡æµä¸­æ‰€æœ‰æ²¡ä¸Šqueue1çš„ä»»åŠ¡å½“å‰æ—¶é—´
#
#             # å°†task_queue1ä¸­çš„ä»»åŠ¡è¿›è¡Œè°ƒåº¦
#             for task in task_queue1:
#                 node=decode1(individual, task, nodes, taskflows, pset)#ä¸ºæ‰€æœ‰æ»¡è¶³è¦æ±‚çš„ä»»åŠ¡é€‰æ‹©èŠ‚ç‚¹,decode1å‡½æ•°ä¸­éœ€è¦å¢åŠ ä¸€ä¸ªçº¦æŸæ¡ä»¶ï¼Œåˆ¤æ–­èŠ‚ç‚¹çš„ramï¼Œgpuï¼Œcpuå¤Ÿä¸å¤Ÿç”¨ï¼Œè¦åœ¨å¤Ÿç”¨çš„èŠ‚ç‚¹ä¸­é€‰æ‹©
#                 task.node=node
#                 if task.present_time>=node.begin_idle_time:#taskçš„å½“å‰æ—¶é—´å¤§äºç­‰äºèŠ‚ç‚¹çš„ç©ºé—²æ—¶é—´
#                     computing_Task_time=computing_Task(task,node)+computing_upload_time(task,node)
#                     endtime=task.present_time+computing_Task_time#taskå®Œæˆæ—¶é—´=taskå½“å‰æ—¶é—´+taskè®¡ç®—æ—¶é—´ round(a, 1)
#                     task.endtime=endtime
#                     queue2.append((task,endtime))#æ·»åŠ å…ƒç»„
#                     node.begin_idle_time=endtime#nodeçš„ç©ºé—²æ—¶é—´ä¿®æ”¹ä¸ºtaskå®Œæˆæ—¶é—´
#                 else:
#                     node.waiting_queue.append(task)
#                 queue1 = [item for item in queue1 if item[0] != task]#åœ¨queue1ä¸­åˆ é™¤ä»»åŠ¡
#
#         if len(task_queue2)!=0 :#åœ¨queue1å’Œqueue2ä¸­æ—¶é—´æœ€å°çš„ä»»åŠ¡åœ¨queue2
#             for finish_event in task_queue2:#æ ‡è®°ä»»åŠ¡å·²å®Œæˆ
#                 finish_event.finish=True
#             present_time_update(present_time=queue2[0][1],taskflows=taskflows)#æ›´æ–°æ‰€æœ‰queue2å’Œqueue1ä¸­ä»»åŠ¡å’Œæ‰€æœ‰nodeä¸­ç­‰å¾…é˜Ÿåˆ—ä¸­ä»»åŠ¡çš„å½“å‰æ—¶é—´ å’Œé¢„å¤„ç†ä»»åŠ¡æµä¸­æ‰€æœ‰æ²¡ä¸Šqueue1çš„ä»»åŠ¡å½“å‰æ—¶é—´(é™¤äº†å·²å®Œæˆçš„ä»»åŠ¡)
#
#
#             for task in task_queue2:
#                 i=task.taskflow_id#ä½ç½®
#                 TaskFlow=taskflows[i]#éœ€è¦æ‰¾åˆ°taskflowåœ¨taskflowsä¸­çš„ä½ç½®
#                 if len(task.descendant)!=0:#è¿™ä¸ªä»»åŠ¡æœ‰åç»§èŠ‚ç‚¹
#                     a=task.descendant #taskçš„æ‰€æœ‰åç»§ä¸‹æ ‡
#                     id=TaskFlow.tasks.index(task) #taskåœ¨tasksä¸­çš„ä¸‹æ ‡
#                     descendant_tasks=[] #åœ¨taskçš„åç»§ä¸­æ‰¾åˆ°æ‰€æœ‰å‰ç½®ä¸º0çš„task
#                     for b in a:
#                         TaskFlow.tasks[b].predecessor.remove(id)                              #æ‰€æœ‰ä»»åŠ¡åˆ é™¤è¿™ä¸ªå‰ç»§ï¼Œå‘åç»§ä¼ é€’ä¿¡æ¯
#                         if len(TaskFlow.tasks[b].predecessor)==0:#åç»§ä»»åŠ¡æ²¡æœ‰äº†æ‰€æœ‰çš„å‰ç»§ä»»åŠ¡
#                             descendant_tasks.append(TaskFlow.tasks[b])
#                     for descendant_task in descendant_tasks:
#                         queue1.append((descendant_task,descendant_task.present_time))#æ·»åŠ å…ƒç»„#è¯¥ä»»åŠ¡ä¸Šqueue1,å¸¦ç€å½“å‰æ—¶é—´ç»„æˆçš„å…ƒç»„
#
#                 else:#æ²¡æœ‰åç»§
#                     TaskFlow.finish_time=max(TaskFlow.finish_time,queue2[0][1])#æ›´æ–°ä»»åŠ¡æµçš„å®Œæˆæ—¶é—´ å–æœ€å¤§å€¼
#                 if len(task.node.waiting_queue)!=0:#ä»»åŠ¡æ‰€åœ¨èŠ‚ç‚¹çš„ç­‰å¾…é˜Ÿåˆ—ä¸ä¸ºç©º
#                     next_task=decode2(individual, task.node, taskflows,nodes, pset)#ä»»åŠ¡æ‰€åœ¨èŠ‚ç‚¹åœ¨å…¶æ‰€åœ¨é˜Ÿåˆ—ä¸­é€‰æ‹©ä¸€ä¸ªä»»åŠ¡
#                     task.node.waiting_queue.remove(next_task)
#                     computing_Task_time = computing_Task(next_task,task.node)+computing_upload_time(next_task,task.node)+0.1*computing_upload_time(task,task.node) #åŒ…æ‹¬ä¸Šä¸ªä»»åŠ¡ç»™åç»§ä¼ é€’æ¶ˆæ¯çš„æ—¶é—´
#                     next_task.endtime=next_task.present_time+computing_Task_time#taskå®Œæˆæ—¶é—´=taskå½“å‰æ—¶é—´+taskè®¡ç®—æ—¶é—´
#                     queue2.append((next_task,next_task.endtime))#æ·»åŠ å…ƒç»„
#
#                     task.node.begin_idle_time=next_task.endtime#nodeçš„ç©ºé—²æ—¶é—´ä¿®æ”¹ä¸ºtaskå®Œæˆæ—¶é—´ ,è¿™é‡Œéœ€è¦è€ƒè™‘æ˜¯å¦ä¿®æ”¹äº†nodeçš„æœ¬ä½“å€¼
#                 queue2 = [item for item in queue2 if item[0] != task]#åœ¨queue1ä¸­åˆ é™¤ä»»åŠ¡#åœ¨queue2ä¸­åˆ é™¤ä»»åŠ¡
#
#     sum_time=0
#     taskflows_number=0
#     for j in taskflows[10:]:#éå†éå‰10ä¸ªä»»åŠ¡æµç®—å‡ºä»»åŠ¡æµçš„å¹³å‡å®Œæˆæ—¶é—´
#         taskflows_number+=1
#         #print(j.finish_time,j.all_arrive_time)
#         sum_time+=(j.finish_time-j.all_arrive_time)
#     return (sum_time/taskflows_number,)

def random_value():
    return random.randint(-1, 1)
# å®šä¹‰å‘½åå‡½æ•°æ¥æ›¿æ¢ lambda
def get_fitness_values(individual):
    return individual.fitness.values

def get_max_tree_height(individual):
    return max([tree.height for tree in individual])

def main_dual_tree():
    nodes = createNode(NUM_NODES,0)
    taskflows=createTaskFlows(NUM_TASKFLOWS,0,0)
    pset = []
    for idx in range(2):
        if idx == 0:
            pset1 = gp.PrimitiveSet("MAIN", 4)
            pset1.addPrimitive(operator.add, 2)
            pset1.addPrimitive(operator.sub, 2)
            pset1.addPrimitive(operator.mul, 2)
            pset1.addPrimitive(protect_div, 2)
            #pset1.addPrimitive(np.divide, 2)
            pset1.addPrimitive(operator.neg, 1)
            pset1.addPrimitive(max, 2)
            pset1.addPrimitive(min, 2)
            #pset1.addEphemeralConstant("rand101", lambda: random.randint(-1, 1))

            pset1.renameArguments(ARG0='TCT')  # ä»»åŠ¡çš„è®¡ç®—æ—¶é—´ tct
            pset1.renameArguments(ARG1='TWT')  # ä»»åŠ¡çš„ç­‰å¾…æ—¶é—´=ä»»åŠ¡çš„åˆ°è¾¾æ—¶é—´-ä»»åŠ¡çš„å½“å‰æ—¶é—´ twt
            pset1.renameArguments(ARG2='TNC')  # ä»»åŠ¡çš„åç»§æ•°é‡ tnc
            #pset1.renameArguments(ARG3='ACT')  # åç»§èŠ‚ç‚¹çš„å¹³å‡å®Œæˆæ—¶é—´ act
            pset1.renameArguments(ARG3='TUT')  # ä»»åŠ¡çš„ä¸Šä¼ æ—¶é—´  tut


            pset.append(pset1)

        elif idx == 1:
            pset2 = gp.PrimitiveSet("MAIN", 5)
            pset2.addPrimitive(operator.add, 2)
            pset2.addPrimitive(operator.sub, 2)
            pset2.addPrimitive(operator.mul, 2)
            pset2.addPrimitive(protect_div, 2)
            #pset2.addPrimitive(np.divide, 2)
            pset2.addPrimitive(operator.neg, 1)
            pset2.addPrimitive(max, 2)
            pset2.addPrimitive(min, 2)

            pset2.renameArguments(ARG0='TCT')  # ä»»åŠ¡çš„è®¡ç®—æ—¶é—´
            pset2.renameArguments(ARG1='TWT')  # ä»»åŠ¡çš„ç­‰å¾…æ—¶é—´=ä»»åŠ¡çš„åˆ°è¾¾æ—¶é—´-ä»»åŠ¡çš„å½“å‰æ—¶é—´
            pset2.renameArguments(ARG2='TNC')  # ä»»åŠ¡çš„åç»§æ•°é‡
            #pset2.renameArguments(ARG3='NTQ')  # ç¬¬äºŒä¸ªæ ‘é˜Ÿåˆ—ä¸­ä»»åŠ¡ä¸ªæ•° ntq
            pset2.renameArguments(ARG3='TPS')  # ä»»åŠ¡çš„ç»™åç»§ä¼ é€’æ¶ˆæ¯çš„æ—¶é—´ tps
            pset2.renameArguments(ARG4='ACT')  # åç»§èŠ‚ç‚¹çš„å¹³å‡å®Œæˆæ—¶é—´ act
            pset.append(pset2)

    # åˆ›å»ºä¸€ä¸ªé€‚åº”åº¦ç±»å’Œä¸ªä½“ç±»ï¼Œä¸ªä½“ç”±å¤šæ£µæ ‘ç»„æˆ
    creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMin)

    toolbox = base.Toolbox()
    toolbox.register("expr", gp.genHalfAndHalf, min_=2, max_=4)
    toolbox.register("individual", initIndividual, creator.Individual, toolbox.expr, pset=pset, size=NUM_TREES)  # å‡è®¾æˆ‘ä»¬åˆ›å»º2ä¸ªæ ‘
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    toolbox.register("evaluate", work_processing)#ä¸èƒ½ç»‘å®štaskflows=taskflows,nodes=nodes
    toolbox.register("select", tools.selTournament, tournsize=TOURNAMENT_SIZE)
    toolbox.register("mate", cxOnePointListOfTrees)
    toolbox.register("mutate", mutUniformListOfTrees)
    toolbox.register("compile", gp.compile)

    population = toolbox.population(n=POP_SIZE)
    hof = tools.HallOfFame(1)
    stats_fit = tools.Statistics(key=get_fitness_values)
    stats_size = tools.Statistics(key=get_max_tree_height)
    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)
    mstats.register("avg", np.mean)
    mstats.register("std", np.std)
    mstats.register("min", np.min)
    mstats.register("max", np.max)
    pop, log ,genre_min_fitness_values,elite= eaSimple(population=population,
                                                       toolbox=toolbox,
                                                       taskflows=taskflows,
                                                       nodes=nodes,
                                                       num_TaskFlow=NUM_TASKFLOWS,
                                                       num_nodes=NUM_NODES,
                                                       cxpb=CXPB,
                                                       mutpb=MUTPB,
                                                       ngen=NGEN,
                                                       elitism=ELITISM_NUM,
                                                       pset=pset,
                                                       llm_interface=LLM_INTERFACE,
                                                       min_fitness_values=[],
                                                       genre_min_fitness_values=[],
                                                       stats=mstats,
                                                       halloffame=hof,
                                                       verbose=True)

    # æŸ¥çœ‹æœ€ä½³ä¸ªä½“
    best_ind = hof[0]
    print('Best individual fitness:', best_ind.fitness)
    leaf_ratio_result=[]
    for tree in elite:
        # plot_a_tree(tree)

        # ç»Ÿè®¡æ¯ç§ç»ˆç«¯çš„æ•°é‡
        leaf_count = count_leaf_types(tree)

        # è®¡ç®—æ ‘ä¸­æ‰€æœ‰ç»ˆç«¯çš„æ€»æ•°
        total_leaves = sum(leaf_count.values())

        # è®¡ç®—æ¯ç§ç»ˆç«¯çš„æ¯”ä¾‹ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨OrderedDictä¸­
        leaf_ratio = OrderedDict((key, value / total_leaves) for key, value in leaf_count.items())
        leaf_ratio_result.append(leaf_ratio)
    return  genre_min_fitness_values,leaf_ratio_result

def keyadd(p,x):
    all_keys = set(p.keys()).union(x.keys())
    result = OrderedDict()
    for key in all_keys:
        result[key] = p.get(key, 0) + x.get(key, 0)
    return result

if __name__ == '__main__':

    #genre_min_fitness_values_sum=[526, 440, 450, 437, 429 ,442, 421.2 ,422, 410 ,412 ,406 ,381.6 ,392 ,375, 367 ,377.2, 379.3 ,367 ,369, 372, 358, 357 ,358 ,361,367.5 ,358, 362 ,368 ,360.4 ,361 ,363, 358.6 ,373, 368.1, 368.4 ,360 ,368 ,375 ,366 ,356, 367, 362 ,358.6 ,366.6 ,356, 357.3, 357, 356, 354]
    # æ‰€æœ‰è¿è¡Œçš„ç»“æœæ±‡æ€»
    run_fitness_history = []
    # è®°å½•æ¯ä¸€ä»£çš„æµ‹è¯•é›†æœ€å°é€‚åº”åº¦çš„ç´¯åŠ å€¼
    genre_min_fitness_values_sum = [0] * NGEN
    # è®°å½•æ¯æ£µæ ‘çš„å¶å­ç±»å‹ç»Ÿè®¡æ¯”ä¾‹ç´¯åŠ å€¼
    leaf_ratio_result_sum = [OrderedDict() for _ in range(NUM_TREES)]
    # NUM_RUNS æ¬¡ç‹¬ç«‹è¿è¡Œ
    for _ in range(NUM_RUNS):
        # æ¯æ¬¡ç‹¬ç«‹è¿è¡Œåï¼Œå¾—åˆ°æ¯ä¸€ä»£çš„æµ‹è¯•é›†çš„æœ€å°é€‚åº”åº¦ï¼Œä»¥åŠæ¯æ£µæ ‘çš„å¶å­æ¯”ä¾‹ç»Ÿè®¡
        genre_min_fitness_values,leaf_ratio_result=main_dual_tree()

        run_fitness_history.append(genre_min_fitness_values)
        genre_min_fitness_values_sum = [a + b for a, b in zip(genre_min_fitness_values, genre_min_fitness_values_sum)]
        leaf_ratio_result_sum=[keyadd(a,b) for a,b in zip(leaf_ratio_result,leaf_ratio_result_sum)]

    genre_min_fitness_values_sum=[a / NUM_RUNS  for a in genre_min_fitness_values_sum]


    print(leaf_ratio_result_sum) 
    print(run_fitness_history)

    # min_fitness_trend(genre_min_fitness_values_sum)



