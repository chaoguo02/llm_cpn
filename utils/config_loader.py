import os

import yaml

from utils.readAndwrite import ensure_directory_exists, write_json

# # **ğŸ”¹ åŸºç¡€è·¯å¾„**
# BASE_PATH = "../gp_records"
# LLM_PATH = "qwen"
#
# # **ğŸ”¹ æ–‡ä»¶è·¯å¾„æ ¼å¼**
# PATH_TEMPLATES = {
#     "train_fitness_cache": f"{BASE_PATH}/caches/func{{function_id}}/train_fitness_func{{function_id}}_exp{{experiment_id}}.json",
#     "test_fitness_cache": f"{BASE_PATH}/caches/func{{function_id}}/test_fitness_func{{function_id}}_exp{{experiment_id}}.json",
#     "results": f"{BASE_PATH}/results/func{{function_id}}/holdout_func{{function_id}}_exp{{experiment_id}}.jsonl",
#     "first_generation_cache": f"{BASE_PATH}/records/func{{function_id}}/first_generation_func{{function_id}}_exp{{experiment_id}}.json",
#     "experiment_time_log": f"{BASE_PATH}/timelogs/func{{function_id}}/experiment_time_log_func{{function_id}}.json",
#     "init_expressions": f"../datasets/{LLM_PATH}_expressions.jsonl",
#     "train_data": "../datasets/fitness_cases{function_id}.csv",
#     "test_data": "../datasets/hold_out{function_id}.csv",
# }

def load_config(config_path):
    """ åŠ è½½ YAML é…ç½®æ–‡ä»¶ """
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")

    try:
        with open(config_path, "r", encoding="utf-8") as file:
            return yaml.safe_load(file)
    except yaml.YAMLError as e:
        raise ValueError(f"âŒ YAML è§£æé”™è¯¯: {e}")
    except Exception as e:
        raise RuntimeError(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")


def generate_file_paths(function_id, experiment_id, base_path, llm_path):
    """ ç”Ÿæˆ GP ç›¸å…³æ–‡ä»¶è·¯å¾„ï¼Œå¹¶ç¡®ä¿è·¯å¾„å­˜åœ¨ """
    path_templates = {
        "train_fitness_cache": f"{base_path}/caches/func{{function_id}}/train_fitness_func{{function_id}}_exp{{experiment_id}}.json",
        "test_fitness_cache": f"{base_path}/caches/func{{function_id}}/test_fitness_func{{function_id}}_exp{{experiment_id}}.json",
        "results": f"{base_path}/results/func{{function_id}}/holdout_func{{function_id}}_exp{{experiment_id}}.jsonl",
        "first_generation_cache": f"{base_path}/records/func{{function_id}}/first_generation_func{{function_id}}_exp{{experiment_id}}.jsonl",
        "experiment_time_log": f"{base_path}/timelogs/func{{function_id}}/experiment_time_log_func{{function_id}}.json",
        "init_expressions": f"../datasets/raw_{llm_path}_expressions.jsonl",
        "train_data": "../datasets/fitness_cases{function_id}.csv",
        "test_data": "../datasets/hold_out{function_id}.csv",
    }

    if llm_path:
        # path_templates["inheritance_expressions"] = f"../data/{llm_path}_first_generation_func{{function_id}}_exp{{experiment_id}}.jsonl"
        path_templates["inheritance_expressions"] = f"../datasets/raw_{llm_path}_expressions.jsonl"

    # **ğŸ”¹ æ ¼å¼åŒ–æ‰€æœ‰è·¯å¾„**
    paths = {key: value.format(function_id=function_id, experiment_id=experiment_id) for key, value in
             path_templates.items()}

    # # **ğŸ”¹ ç¡®ä¿è·¯å¾„å­˜åœ¨**
    # for path in paths.values():
    #     ensure_directory_exists(path)
    #     if not os.path.exists(path):
    #         write_json(path, {} if path.endswith(".json") else [])
    # åˆ›å»ºæ–‡ä»¶å¤¹ + åˆå§‹åŒ–ç©ºæ–‡ä»¶
    for key, path in paths.items():
        ensure_directory_exists(path)
        if not os.path.exists(path):
            if key in ["train_fitness_cache", "test_fitness_cache", "experiment_time_log"]:
                write_json(path, {})  # åˆå§‹åŒ–ä¸º {} çš„ JSON æ–‡ä»¶
            elif path.endswith(".jsonl"):
                open(path, 'w', encoding='utf-8').close()  # åˆ›å»ºç©º JSONL æ–‡ä»¶
            else:
                # å¯¹äº .csv æˆ–å…¶ä»–ï¼Œåªåˆ›å»ºç©ºæ–‡ä»¶
                open(path, 'w', encoding='utf-8').close()

    # **ğŸ”¹ è°ƒè¯•è¾“å‡º**
    print("\nğŸ”¹ Generated File Paths:")
    for key, value in paths.items():
        print(f"{key}: {value}")

    return paths