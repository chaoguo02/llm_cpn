import operator
import random
import copy
import json
import os
from deap import gp
from collections import OrderedDict
from baselines.my_fifo import get_fifo_node_score, get_fifo_task_score
from core_function.pset_toolbox_settings import init_pset_toolbox
from core_function.running_process import eaSimple
from core_function.data_loader import createNode, createTaskFlows
from core_function.evaluate import work_processing
from core_function.update_time import computing_Task, computing_upload_time
from dirty_work.dirty_works import protect_div, count_leaf_types


#  ç»Ÿä¸€å‚æ•°è®¾ç½®
NUM_NODES = 5                 # èŠ‚ç‚¹æ•°
NUM_TASKFLOWS = 10             # ä»»åŠ¡æµæ•°
POP_SIZE = 10                  # ç§ç¾¤è§„æ¨¡
NGEN = 2                       # è¿›åŒ–ä»£æ•°
CXPB = 0.8                     # äº¤å‰æ¦‚ç‡
MUTPB = 0.1                    # å˜å¼‚æ¦‚ç‡
TOURNAMENT_SIZE = 1           # é”¦æ ‡èµ›é€‰æ‹©è§„æ¨¡
HEIHT_LIMIT = 6               # æœ€å¤§æ ‘é«˜
NUM_TREES = 2                 # æ¯ä¸ªä¸ªä½“ä¸­æ ‘çš„æ•°é‡
NUM_RUNS = 1                # é‡å¤è¿è¡Œæ¬¡æ•°ï¼ˆç”¨äºç»Ÿè®¡å‡å€¼ï¼‰
ELITISM_NUM = int(POP_SIZE * 0.05)  # ç²¾è‹±ä¸ªä½“çš„æ•°é‡
NUM_TEST_SETS = 1             # æµ‹è¯•é›†æ•°é‡
NUM_TRAIN_SETS = 1             # è®­ç»ƒé›†æ•°é‡
BASE_SEED = 10000              # è®­ç»ƒé›†æˆ‘ä»¬ä»10000å¼€å§‹

def initIndividual(container, func, pset, size):
    return container(gp.PrimitiveTree(func(pset[i])) for i in range(size))

def cxOnePointListOfTrees(ind1, ind2):
    print("type:", type(ind1))
    for idx, (tree1, tree2) in enumerate(zip(ind1, ind2)):
        print(f"\n===== äº¤å‰å¤„ç†ç¬¬ {idx} æ£µå­æ ‘ =====")
        print("ğŸ”µ åŸå§‹ tree1 (str):", str(tree1))
        print("ğŸ”µ åŸå§‹ tree2 (str):", str(tree2))

        HEIGHT_LIMIT = 8
        dec = gp.staticLimit(key=operator.attrgetter("height"), max_value=HEIGHT_LIMIT)
        tree1, tree2 = dec(gp.cxOnePoint)(tree1, tree2)
        print("ğŸŸ¢ äº¤å‰å tree1_new (str):", str(tree1))
        print("ğŸŸ¢ äº¤å‰å tree2_new (str):", str(tree2))
        ind1[idx], ind2[idx] = tree1, tree2

    return ind1, ind2

def mutUniformListOfTrees(individual, expr, pset):
    for idx, tree in enumerate(individual):
        HEIGHT_LIMIT = 8
        dec = gp.staticLimit(key=operator.attrgetter("height"), max_value=HEIGHT_LIMIT)
        tree, = dec(gp.mutUniform)(tree, expr=expr,pset=pset[idx])
        individual[idx] = tree

    return (individual,)

def varAnd(population, toolbox, cxpb, mutpb):
    offspring = [toolbox.clone(ind) for ind in population]
    evlpb=cxpb/(cxpb+mutpb)
    if random.random() < evlpb:
        for i in range(1, len(offspring), 2):
            offspring[i - 1], offspring[i] = toolbox.mate(offspring[i - 1],
                                                          offspring[i])

            del offspring[i - 1].fitness.values, offspring[i].fitness.values

    else:
        for i in range(len(offspring)):
            offspring[i], = toolbox.mutate(offspring[i])
            del offspring[i].fitness.values

    return offspring

def keyadd(p,x):
    all_keys = set(p.keys()).union(x.keys())
    result = OrderedDict()
    for key in all_keys:
        result[key] = p.get(key, 0) + x.get(key, 0)
    return result

def sortPopulation(toolbox, population):
    # å…‹éš†ä¸ªä½“ï¼Œé¿å…ä¿®æ”¹åŸå§‹ç§ç¾¤
    populationCopy = [toolbox.clone(ind) for ind in population]
    # ä½¿ç”¨ sorted æŒ‰é€‚åº”åº¦å‡åºæ’åº
    sorted_population = sorted(populationCopy, key=lambda ind: ind.fitness.values)
    return sorted_population

def record_best_individual_log(individual, pre_generated_taskflows, nodes, pset, generation_index, run_index, base_dir="best_ind_logs"):

    test_taskflows_sample = copy.deepcopy(pre_generated_taskflows[0])
    nodes_log = copy.deepcopy(nodes)

    _, log_dict = work_processing(individual, test_taskflows_sample, nodes_log, pset, return_log=True)

    log_dict["individual_expressions"] = [str(tree) for tree in individual]

    run_dir = os.path.join(base_dir, f"run_{run_index}")
    os.makedirs(run_dir, exist_ok=True)

    log_path = os.path.join(run_dir, f"gen_{generation_index}_log.json")
    with open(log_path, "w", encoding='utf-8') as f:
        json.dump(log_dict, f, indent=2, ensure_ascii=False)

def decode1(individual, task, nodes, taskflows, pset):
    try:
        heuristic_1 = gp.compile(expr=individual[0], pset=pset[0])
        scores = []
        for node in nodes:
            if (node.cpu_available >= task.cpu_require and node.ram_available >= task.ram_require and
                node.gpu_available >= task.gpu_require):
                score = heuristic_1(computing_Task(task, node), task.present_time - task.arrivetime,
                    len(task.descendant), computing_upload_time(task, node), get_fifo_node_score(node))
                scores.append((node, score))
        if not scores:
            return None
        return max(scores, key=lambda x: x[1])[0]
    except Exception as e:
        print(f"[âŒ å¼‚å¸¸] decode1 å¤„ç†ä»»åŠ¡ {task.global_id} æ—¶å‡ºé”™ï¼š{e}")
        return None

def decode2(individual, node, taskflows, nodes, pset):
    try:
        heuristic_2 = gp.compile(expr=individual[1], pset=pset[1])
        scores = []
        for task in node.waiting_queue:
            if (node.cpu_available >= task.cpu_require and node.ram_available >= task.ram_require and
                node.gpu_available >= task.gpu_require):
                k = task.taskflow_id
                score = heuristic_2(computing_Task(task, node), task.present_time - task.arrivetime, len(task.descendant),
                    taskflows[k].find_descendant_avg_time(taskflows, task, nodes),
                    0.1 * computing_upload_time(task, node), get_fifo_task_score(task))
                scores.append((task, score))
        if not scores:
            return None
        return max(scores, key=lambda x: x[1])[0]
    except Exception as e:
        print(f"[âŒ å¼‚å¸¸] decode2 é€‰æ‹©èŠ‚ç‚¹ {node.id} çš„ç­‰å¾…ä»»åŠ¡æ—¶å‡ºé”™ï¼š{e}")
        return None



def main_dual_tree(num_run):
    nodes = createNode(NUM_NODES,0)
    pre_generated_taskflows = []
    for i in range(NUM_TEST_SETS):
        taskflow = createTaskFlows(NUM_TASKFLOWS,1,i)
        pre_generated_taskflows.append(taskflow)

    pset, toolbox = init_pset_toolbox(TOURNAMENT_SIZE)

    population = toolbox.population(n=POP_SIZE)
    pop,genre_min_fitness_values,elite= eaSimple(population=population,
                                                       toolbox=toolbox,
                                                       nodes=nodes,
                                                       pre_generated_taskflows=pre_generated_taskflows,
                                                       num_TaskFlow=NUM_TASKFLOWS,
                                                       cxpb=CXPB,
                                                       mutpb=MUTPB,
                                                       ngen=NGEN,
                                                       elitism=ELITISM_NUM,
                                                       pset=pset,
                                                       num_run = num_run,
                                                       base_seed = BASE_SEED,
                                                       num_train_sets = NUM_TRAIN_SETS,
                                                       num_test_sets = NUM_TEST_SETS,
                                                       min_fitness_values=[],
                                                       genre_min_fitness_values=[]
                                                 )
    leaf_ratio_result=[]
    for tree in elite:
        # ç»Ÿè®¡æ¯ç§ç»ˆç«¯çš„æ•°é‡
        leaf_count = count_leaf_types(tree)
        # è®¡ç®—æ ‘ä¸­æ‰€æœ‰ç»ˆç«¯çš„æ€»æ•°
        total_leaves = sum(leaf_count.values())
        # è®¡ç®—æ¯ç§ç»ˆç«¯çš„æ¯”ä¾‹ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨OrderedDictä¸­
        leaf_ratio = OrderedDict((key, value / total_leaves) for key, value in leaf_count.items())
        leaf_ratio_result.append(leaf_ratio)
    return genre_min_fitness_values,leaf_ratio_result

if __name__ == '__main__':

    run_fitness_history = []
    # è®°å½•æ¯ä¸€ä»£çš„æµ‹è¯•é›†æœ€å°é€‚åº”åº¦çš„ç´¯åŠ å€¼
    genre_min_fitness_values_sum = [0] * NGEN
    # è®°å½•æ¯æ£µæ ‘çš„å¶å­ç±»å‹ç»Ÿè®¡æ¯”ä¾‹ç´¯åŠ å€¼
    leaf_ratio_result_sum = [OrderedDict() for _ in range(NUM_TREES)]
    # NUM_RUNS æ¬¡ç‹¬ç«‹è¿è¡Œ
    for num_run in range(NUM_RUNS):
        # æ¯æ¬¡ç‹¬ç«‹è¿è¡Œåï¼Œå¾—åˆ°æ¯ä¸€ä»£çš„æµ‹è¯•é›†çš„æœ€å°é€‚åº”åº¦ï¼Œä»¥åŠæ¯æ£µæ ‘çš„å¶å­æ¯”ä¾‹ç»Ÿè®¡
        genre_min_fitness_values, leaf_ratio_result = main_dual_tree(num_run)

        run_fitness_history.append(genre_min_fitness_values)
        genre_min_fitness_values_sum = [a + b for a, b in
                                        zip(genre_min_fitness_values, genre_min_fitness_values_sum)]
        leaf_ratio_result_sum = [keyadd(a, b) for a, b in zip(leaf_ratio_result, leaf_ratio_result_sum)]

    genre_min_fitness_values_sum = [a / NUM_RUNS for a in genre_min_fitness_values_sum]



